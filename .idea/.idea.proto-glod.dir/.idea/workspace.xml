<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ChangeListManager">
    <list default="true" id="c23cf342-e8ec-4564-9178-d19a6f43953d" name="Changes" comment="Rendering &amp; CharacterArt: HLSL Shaders &amp; Metahumans&#10;&#10;Shaders:&#10;- I created a variety of Materials using HLSL code in a custom node from a series of video tutorials (Unreal Engine 5 Tutorial - Technical Shading - Introduction To HLSL | https://youtu.be/lsXB1PQdGx0).&#10;&#10;- I am particularly interested in two of them: The one that produces a stepped gradient (like a rainbow), interpolation between two colors in either horizontally or vertically oriented segments the amount of segments can be defined with a scalar value making the rainbow less or more smooth.The second one is the raymarching example that draws a shape inside the silhouette of any other shape, I feel like the un-shaded version (a solid color sphere with no light and shadow) can be another very cool looking visual motif, in addition with the point displacement oscillation effect.&#10;&#10;Metahuman:&#10;&#10;- I created a Metahuman character template. I used the character creator web editor to get as close as I could to the result that I wanted (I was aiming to make it look vaguely like me), then I added it to my UE project via Quixel Bridge in the editor. I then exported the mesh and relevant texture assets for iteration in Blender for sculpting, Substance Designer for procedural shading, and Substance Painter for texturing. I created work files in all of those DCCs (Didgital Content Creators), and modified the Normal map of the face by adding a crystal/rock effect with a Voronoi fractal pattern.&#10;&#10;- The internet sources for my metahuman workflow can be found in Ideation\moodboards\references\Obsidian - metahuman character moodboard --canvas file.&#10;&#10;- Also in that canvas file, viewable in Obsidian the software, is a detailed technical process flow-chart that is the result of my investigation into ways of affecting the metahumann workflow for greatest customization and in-depth iteration. Some questions surfaced after I presented the workflow to a tech artist friend (Sascha), and I will work on trying to answer them in the coming days.">
      <change beforePath="$PROJECT_DIR$/.idea/.idea.proto-glod.dir/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/.idea.proto-glod.dir/.idea/workspace.xml" afterDir="false" />
    </list>
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="MarkdownSettingsMigration">
    <option name="stateVersion" value="1" />
  </component>
  <component name="MetaFilesCheckinStateConfiguration" checkMetaFiles="true" />
  <component name="ProjectId" id="2PhGd0g5KZsI4ucyQU5ogz7359p" />
  <component name="ProjectViewState">
    <option name="hideEmptyMiddlePackages" value="true" />
    <option name="showLibraryContents" value="true" />
  </component>
  <component name="PropertiesComponent">{
  &quot;keyToString&quot;: {
    &quot;RunOnceActivity.OpenProjectViewOnStart&quot;: &quot;true&quot;,
    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
    &quot;WebServerToolWindowFactoryState&quot;: &quot;false&quot;,
    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;
  },
  &quot;keyToStringList&quot;: {
    &quot;rider.external.source.directories&quot;: [
      &quot;C:\\Users\\kisho\\AppData\\Roaming\\JetBrains\\Rider2022.3\\resharper-host\\DecompilerCache&quot;,
      &quot;C:\\Users\\kisho\\AppData\\Roaming\\JetBrains\\Rider2022.3\\resharper-host\\SourcesCache&quot;,
      &quot;C:\\Users\\kisho\\AppData\\Local\\Symbols\\src&quot;
    ]
  }
}</component>
  <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="c23cf342-e8ec-4564-9178-d19a6f43953d" name="Changes" comment="" />
      <created>1683901983826</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1683901983826</updated>
      <workItem from="1683901985469" duration="10381000" />
      <workItem from="1686857868395" duration="11235000" />
      <workItem from="1691291770142" duration="3284000" />
    </task>
    <task id="LOCAL-00001" summary="ProtoGlod: Technical investigations, game mechanics and knowledge bases&#10;&#10;- I implemented an aim UI to the HUD of the character that changes states if it is hovering over an interactable object. &#10;- I also documented the process from a technical standpoint by taking screenshots of the tutorial where I learned the technique.&#10;- I've gone on a rabbit hole of tech investigations, and I have now incorporated Obsidian, a text editor, to build a 'knowledge base' of everything (or most things) I learn by watching tutorials and adapting the contents to my needs.&#10;- Some re-shuffling of priorities is occuring as I come into contact with the 'tasks' that I planned for in my schedule. I talk more about this in my process journal, and it's an ongoing conversation with myself.">
      <created>1684331579880</created>
      <option name="number" value="00001" />
      <option name="presentableId" value="LOCAL-00001" />
      <option name="project" value="LOCAL" />
      <updated>1684331579880</updated>
    </task>
    <task id="LOCAL-00002" summary=" ProtoGlod: Knoledge base entries and story writing&#10; &#10; - I think I have concluded my tech investigation black hole for now. I have a ton of material related to blueprint communication and interaction implementation to refer back to as a I proceed.&#10; &#10; - I wrote the start of a script for the narrative. I went for a stream of consciousness style where every character's dialogue is mushed together into obsidian's inner dialogue. I'm thinking of this as a way to represent the role of perspective in narrative and the way we process our experiences of the world. Everything filtered through the interface of our own minds. So far I've incorporated only two voices --obsidian's and tezcatlipoca's--  I am curious to see how it turns out when I add more characters in to the mix.">
      <created>1684718344145</created>
      <option name="number" value="00002" />
      <option name="presentableId" value="LOCAL-00002" />
      <option name="project" value="LOCAL" />
      <updated>1684718344145</updated>
    </task>
    <task id="LOCAL-00003" summary="CharacterDesign, DevBuild: published development build, created technical character drawings&#10;&#10; - Published an in-progress build to itch.io: https://lm-vega.itch.io/proto-glod-awakening-3d-in-progress-build-1&#10; &#10; - Had some fun trying to figure out how to make the packaged build start in widowed mode at a 1920*1080 resolution. It which turned out to be more complicated that I expected, even tho I had already done it in the past for the Stack Bot bug build. I might have deleted my implementation on the stack bot game mode cause I thought it was 'hacky' solution. I also think the current one is sorta hacky, but I am proud of how I figured it out from the limited info online, and this time I documented the process on my knowledge base. It is definetly not the same solution I used before, I had to learn about the 'user settings' nodes, and I dont know what about my current set up made the previous method unusable (or if it's just the fact that I dont quite remember what it was exactly). &#10; &#10; - I also made a turnabout technical drawing sheet and started modeling Obsidian! I had a lot of fun coloring the 3/4 view and I even drew some props; the gemboid, a backpack, and a jaguar mask I that I really like. I have now started to block-out the character in 3D, using the Void Being model as a base mesh. I'm sculpting on Nomad Sculpt on the Ipad.">
      <created>1686858958598</created>
      <option name="number" value="00003" />
      <option name="presentableId" value="LOCAL-00003" />
      <option name="project" value="LOCAL" />
      <updated>1686858958598</updated>
    </task>
    <task id="LOCAL-00004" summary="Gameplay: Success! Via the power of friendship&#10;&#10;- I have been really struggling with the implementation of the core object swapping mechanic. Getting around the communication tangle through interfaces and actors (objects), and blueprint components, and unknown gaps in my knowledge. I just could not get it to work. Not only did I not know a bunch of thing; I didnt know that I did not know a whole other bunch of things.&#10;&#10;- This weekend I finally consulted my friend David. He basically unblocked me and intervened in my blueprints in key ways that I would have not figured out om my own. I was tangled up in a number of stacked effects that worked against me. 1) the 'cyclic' implementation of the object swapping interaction was absorbing the mouse click event input --not allowing it to be used by my new blueprint code. We turned off 'absorb input' on the test actor in the level, then got rid of it entirely after it caused more shenanigans (might re-introduce later just for fun). 2) trying to store component data from my selectable objects using the events and variables in the 'selectable object interface' proved to be an unnecessary complication (I'm still using the interface to change the visibility of the highlight decal, via it's events, and to display the interaction indicator UI). Instead we used variables on the character blueprint to store ('get') and 'set' the static mesh components. 3) We had to create 2 'levels' of variables ('mesh' and 'mesh mesh') for the objects in the interaction (targeted, and target objects); one of the variables refers to the static mesh 'component' in the actor blueprint, and the other to the actual static mesh 'asset' in use within that component. 4) Finally and most fundamentally, I had been thinking of the interaction as happening all within the same input (Left Mouse Button); where clicking on an object would store its mesh in a variable, then clicking on another object would swap that object's mesh with the one stored in the variable. Instead we opted to have a separate input (Right Mouse Button) be in charge of the swap, which made it much more simple to conceive of the getting and setting of the static mesh components/ assets in practice, and it makes for a more interesting and clear gameplay experience (at least to me and David at this moment).&#10;&#10;- So the current behaviour goes like this: 1) pressing either left or right mouse button will select the targeted object, highlighting it with an emissive decal and storing its static mesh (using 2 'levels' of variables). 2) Pressing the same input again on the same object will have no effect. 2) Pressing the same input on a different object will 'select' that new object and 'deselect' the old one. 3) The Player must press the opposite mouse button while targeting the second object in order to swap its mesh with the selected object's mesh (if selection was made with the Left Mouse button, the swap must be made with the Right Mouse Button, and vise-versa).&#10;&#10;- Next up for this feature is extending its functionality to work with Left and Right trigger buttons on a gamepad. And to color-code the selected object's highlight decal depending on weather it was selected with the Left or Right input. Hopefully that will help communicate the mechanic better, and help players remember what button should be pressed next to enact the swap during play.&#10;&#10;- I have documented this implementation with screenshots in my knowledge base for future reference.">
      <created>1687209907057</created>
      <option name="number" value="00004" />
      <option name="presentableId" value="LOCAL-00004" />
      <option name="project" value="LOCAL" />
      <updated>1687209907057</updated>
    </task>
    <task id="LOCAL-00005" summary="ProtoGlod: manifesting iterations&#10;- Minor adjustments to level blockout.&#10;- Transcribed additions to the dialogue stream script from my notebook.&#10;- Finalizing 'Iterative Manifestation Analysis &amp; Post-study Report' document. Now housed in Process/process-documents.">
      <created>1687975397628</created>
      <option name="number" value="00005" />
      <option name="presentableId" value="LOCAL-00005" />
      <option name="project" value="LOCAL" />
      <updated>1687975397628</updated>
    </task>
    <option name="localTasksCounter" value="6" />
    <servers />
  </component>
  <component name="TypeScriptGeneratedFilesManager">
    <option name="version" value="3" />
  </component>
  <component name="UnityCheckinConfiguration" checkUnsavedScenes="true" />
  <component name="UnityUnitTestConfiguration" currentTestLauncher="NUnit" />
  <component name="VcsManagerConfiguration">
    <option name="CLEAR_INITIAL_COMMIT_MESSAGE" value="true" />
    <MESSAGE value="ProtoGlod: Technical investigations, game mechanics and knowledge bases&#10;&#10;- I implemented an aim UI to the HUD of the character that changes states if it is hovering over an interactable object. &#10;- I also documented the process from a technical standpoint by taking screenshots of the tutorial where I learned the technique.&#10;- I've gone on a rabbit hole of tech investigations, and I have now incorporated Obsidian, a text editor, to build a 'knowledge base' of everything (or most things) I learn by watching tutorials and adapting the contents to my needs.&#10;- Some re-shuffling of priorities is occuring as I come into contact with the 'tasks' that I planned for in my schedule. I talk more about this in my process journal, and it's an ongoing conversation with myself." />
    <MESSAGE value=" ProtoGlod: Knoledge base entries and story writing&#10; &#10; - I think I have concluded my tech investigation black hole for now. I have a ton of material related to blueprint communication and interaction implementation to refer back to as a I proceed.&#10; &#10; - I wrote the start of a script for the narrative. I went for a stream of consciousness style where every character's dialogue is mushed together into obsidian's inner dialogue. I'm thinking of this as a way to represent the role of perspective in narrative and the way we process our experiences of the world. Everything filtered through the interface of our own minds. So far I've incorporated only two voices --obsidian's and tezcatlipoca's--  I am curious to see how it turns out when I add more characters in to the mix." />
    <MESSAGE value="CharacterDesign, DevBuild: published development build, created technical character drawings&#10;&#10; - Published an in-progress build to itch.io: https://lm-vega.itch.io/proto-glod-awakening-3d-in-progress-build-1&#10; &#10; - Had some fun trying to figure out how to make the packaged build start in widowed mode at a 1920*1080 resolution. It which turned out to be more complicated that I expected, even tho I had already done it in the past for the Stack Bot bug build. I might have deleted my implementation on the stack bot game mode cause I thought it was 'hacky' solution. I also think the current one is sorta hacky, but I am proud of how I figured it out from the limited info online, and this time I documented the process on my knowledge base. It is definetly not the same solution I used before, I had to learn about the 'user settings' nodes, and I dont know what about my current set up made the previous method unusable (or if it's just the fact that I dont quite remember what it was exactly). &#10; &#10; - I also made a turnabout technical drawing sheet and started modeling Obsidian! I had a lot of fun coloring the 3/4 view and I even drew some props; the gemboid, a backpack, and a jaguar mask I that I really like. I have now started to block-out the character in 3D, using the Void Being model as a base mesh. I'm sculpting on Nomad Sculpt on the Ipad." />
    <MESSAGE value="Gameplay: Success! Via the power of friendship&#10;&#10;- I have been really struggling with the implementation of the core object swapping mechanic. Getting around the communication tangle through interfaces and actors (objects), and blueprint components, and unknown gaps in my knowledge. I just could not get it to work. Not only did I not know a bunch of thing; I didnt know that I did not know a whole other bunch of things.&#10;&#10;- This weekend I finally consulted my friend David. He basically unblocked me and intervened in my blueprints in key ways that I would have not figured out om my own. I was tangled up in a number of stacked effects that worked against me. 1) the 'cyclic' implementation of the object swapping interaction was absorbing the mouse click event input --not allowing it to be used by my new blueprint code. We turned off 'absorb input' on the test actor in the level, then got rid of it entirely after it caused more shenanigans (might re-introduce later just for fun). 2) trying to store component data from my selectable objects using the events and variables in the 'selectable object interface' proved to be an unnecessary complication (I'm still using the interface to change the visibility of the highlight decal, via it's events, and to display the interaction indicator UI). Instead we used variables on the character blueprint to store ('get') and 'set' the static mesh components. 3) We had to create 2 'levels' of variables ('mesh' and 'mesh mesh') for the objects in the interaction (targeted, and target objects); one of the variables refers to the static mesh 'component' in the actor blueprint, and the other to the actual static mesh 'asset' in use within that component. 4) Finally and most fundamentally, I had been thinking of the interaction as happening all within the same input (Left Mouse Button); where clicking on an object would store its mesh in a variable, then clicking on another object would swap that object's mesh with the one stored in the variable. Instead we opted to have a separate input (Right Mouse Button) be in charge of the swap, which made it much more simple to conceive of the getting and setting of the static mesh components/ assets in practice, and it makes for a more interesting and clear gameplay experience (at least to me and David at this moment).&#10;&#10;- So the current behaviour goes like this: 1) pressing either left or right mouse button will select the targeted object, highlighting it with an emissive decal and storing its static mesh (using 2 'levels' of variables). 2) Pressing the same input again on the same object will have no effect. 2) Pressing the same input on a different object will 'select' that new object and 'deselect' the old one. 3) The Player must press the opposite mouse button while targeting the second object in order to swap its mesh with the selected object's mesh (if selection was made with the Left Mouse button, the swap must be made with the Right Mouse Button, and vise-versa).&#10;&#10;- Next up for this feature is extending its functionality to work with Left and Right trigger buttons on a gamepad. And to color-code the selected object's highlight decal depending on weather it was selected with the Left or Right input. Hopefully that will help communicate the mechanic better, and help players remember what button should be pressed next to enact the swap during play.&#10;&#10;- I have documented this implementation with screenshots in my knowledge base for future reference." />
    <MESSAGE value="ProtoGlod: manifesting iterations&#10;- Minor adjustments to level blockout.&#10;- Transcribed additions to the dialogue stream script from my notebook.&#10;- Finalizing 'Iterative Manifestation Analysis &amp; Post-study Report' document. Now housed in Process/process-documents." />
    <option name="LAST_COMMIT_MESSAGE" value="ProtoGlod: manifesting iterations&#10;- Minor adjustments to level blockout.&#10;- Transcribed additions to the dialogue stream script from my notebook.&#10;- Finalizing 'Iterative Manifestation Analysis &amp; Post-study Report' document. Now housed in Process/process-documents." />
  </component>
</project>